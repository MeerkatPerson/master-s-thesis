from typing import List, Dict, Tuple
import json
from statistics import median

MICROSECONDS_PER_SECOND = 1000000
MICROSECONDS_TWO_HOURS = 120*60*MICROSECONDS_PER_SECOND

# TODO adjust as needed
home_dir = '/home/joerg_diesel_rules'


def compute_idle_time(ordered_events: List[Tuple[str, int, int]]) -> int:

    idle_time: int = 0

    num_active: int = 0

    begin_idle_time: int = 0

    for event in ordered_events:

        type = event[0]
        timestamp = event[1]
        seed = event[2]

        if type == "CREATE" or type == "FIRST_PAYLOAD":

            if num_active == 0:

                curr_idle_time = (timestamp - begin_idle_time)

                if curr_idle_time < 0:

                    print(
                        "Something went wrong, negative idle time value - are ordered events not ordered?!")

                idle_time += curr_idle_time

            num_active += 1

        elif type == "COMPLETE":

            if num_active == 0:

                print(
                    "Something went wrong, can't complete a stream/flow if none are active!")

            num_active -= 1

            if num_active == 0:

                begin_idle_time = timestamp

    return idle_time


def get_flow_stats(flows: Dict[int, Dict[str, int]]) -> Tuple[List[int], List[int]]:

    flow_durations: List[int] = []

    inter_flow_creation_intervals: List[int] = []

    med_time_to_first_payload_streams: List[int] = []

    last_creation_event: int = 0

    for key, val in flows.items():

        if val["time_to_first_payload_streams"] != []:

            med_time_to_first_payload_streams.append(
                median(val["time_to_first_payload_streams"]))

        else:

            med_time_to_first_payload_streams.append(99999)

        # if this flow was the last one, it was interrupted as the simulation ended, which is at 7200000000 microseconds after the experiment begun
        if val["time_completed"] == None:

            val["time_completed"] = MICROSECONDS_TWO_HOURS

        flow_durations.append(val["time_completed"] - val["first_payload"])

        inter_flow_creation_intervals.append(
            val["time_created"] - last_creation_event)

        last_creation_event = val["time_created"]

    return flow_durations, inter_flow_creation_intervals, med_time_to_first_payload_streams


if __name__ == "__main__":

    ind = 0

    data_dict = dict()

    for i in range(126):

        # 8 client-server pairs per run
        for nr in [1, 2, 3, 4, 5, 6, 7, 8]:

            flow_dict = {"flows": dict(), "ordered_events": []}

            stream_dict = {"streams": dict(), "ordered_events": []}

            # for looking up which stream was created by which flow
            streammodel_seed_to_flowmmodel_seed: Dict[int, int] = dict()

            client_file = open(
                f"/home/joerg_diesel_rules/tgen-results/tgen-traffic-results/run-{i}/client{nr}.tgen.stdout")

            client_lines = client_file.readlines()

            # Probably don't need server perspective since client is the one initiating flows and handling their completion (?)
            # server_file = open(f"../../tgen-traces/{dir}/server{num}.tgen.stdout")
            # server_lines = server_file.readlines()

            # grab the start time (in seconds)
            start_time = int(client_lines[0].split(" ")[2].split(".")[0])

            # for tracking if something went severly wrong during this trace
            fail = False

            for client_line in client_lines:

                client_line_chunks = client_line.split(" ")

                if client_line_chunks[5] == "[_tgengenerator_createFlow]":

                    """
                    2000-01-01 00:56:58 946688218.093764 [message] [tgen-generator.c:382] [_tgengenerator_createFlow] [T] FLOW with mmodel seed 1552343391 was successfully generated by flowgenerator with mmodel seed 3624229543 
                    """

                    # parse the seeds of the flow's mmodel
                    flow_mm_seed_createFlow = int(client_line_chunks[11])

                    # parse creation time, adjusted for the start_time we determined above
                    # split time_unix_seconds.time_microseconds
                    time = client_line_chunks[2].split(".")

                    # grab unix seconds
                    time_unix_seconds = int(time[0])

                    # adjust for start time
                    time_adjusted_seconds = time_unix_seconds - start_time

                    # grab microseconds
                    time_microseconds = int(time[1])

                    # compute total microseconds
                    time_total = time_adjusted_seconds * MICROSECONDS_PER_SECOND + time_microseconds

                    flow_dict["flows"][flow_mm_seed_createFlow] = {
                        "time_created": time_total, "first_payload": None, "num_streams": 0, "all_streams_created": False, "time_completed": None, "time_to_first_payload_streams": []}

                    flow_dict["ordered_events"].append(
                        ("CREATE", time_total, flow_mm_seed_createFlow))

                    flow_mm_seed_createFlow = None  # sanity check

                # this tells us that a flow has created all its streams
                elif (client_line_chunks[5] == "[_tgengenerator_onCompleteHelper]") and (client_line_chunks[10] == "'traffic'"):
                    """
                    2000-01-01 00:06:22 946685182.689991 [message] [tgen-generator.c:293] [_tgengenerator_onCompleteHelper] Generator status for action 'traffic' with mmseed 482765: completed 11 of 11 streams, flow is complete
                    """

                    if client_line_chunks[17] == "0":
                        print(
                            "Found flow that wasn't supposed to create any streams!")

                    # parse the seed of the flow's mmodel
                    flow_mm_seed_completeFlows = int(
                        client_line_chunks[13].split(':')[0])

                    # put info into dict
                    flow_dict["flows"][flow_mm_seed_completeFlows]["all_streams_created"] = True

                    flow_mm_seed_completeFlows = None

                # track info about stream creation
                elif (client_line_chunks[5] == "[_tgengenerator_createStream]"):
                    """
                    2000-01-01 00:05:00 946685100.000000 [message] [tgen-generator.c:448] [_tgengenerator_createStream] [T] STREAM with mmodel seed 3245152722 was successfully generated by flow with mmodel seed 4254684521 
                    """
                    # important: add entry to streammodel_seed_to_flowmmodel_seed
                    stream_mm_seed_createStream: int = int(
                        client_line_chunks[11])
                    flow_mm_seed_createStream: int = int(
                        client_line_chunks[20])

                    streammodel_seed_to_flowmmodel_seed[stream_mm_seed_createStream] = flow_mm_seed_createStream

                    # increase the number of streams active on this flow
                    flow_dict["flows"][flow_mm_seed_createStream]["num_streams"] += 1

                    # split time_unix_seconds.time_microseconds
                    time = client_line_chunks[2].split(".")

                    # grab unix seconds
                    time_unix_seconds = int(time[0])

                    # adjust for start time
                    time_adjusted_seconds = time_unix_seconds - start_time

                    # grab microseconds
                    time_microseconds = int(time[1])

                    # compute total microseconds
                    time_total = time_adjusted_seconds * MICROSECONDS_PER_SECOND + time_microseconds

                    # add info to stream dict
                    stream_dict["streams"][stream_mm_seed_createStream] = {
                        "time_created": time_total, "first_payload": None, "finish": None}

                    stream_mm_seed_createStream = None

                    flow_mm_seed_createStream = None

                # track info about first payload sent (in the direction CLIENT => SERVER) on a stream, which might also be the first payload sent on a flow if the respective stream is the first one created by a flow.
                elif (client_line_chunks[5] == "[tgenmarkovmodel_getNextObservation]") and client_line_chunks[8] == "'tgen.tor-packetmodel-ccs2018.graphml'" and client_line_chunks[12] in ["OBSERVATION_TO_SERVER", "OBSERVATION_TO_ORIGIN"]:
                    """
                    2000-01-01 00:10:51 946685451.633239 [message] [tgen-markovmodel.c:1455] [tgenmarkovmodel_getNextObservation] Markov model 'tgen.tor-packetmodel-ccs2018.graphml' seed 169191960 found OBSERVATION_TO_SERVER with delay of 1497 microseconds
                    """

                    stream_mm_seed_firstPayload: int = int(
                        client_line_chunks[10])

                    flow_mm_seed_firstPayload: int = streammodel_seed_to_flowmmodel_seed[
                        stream_mm_seed_firstPayload]

                    # split time_unix_seconds.time_microseconds
                    time = client_line_chunks[2].split(".")

                    # grab unix seconds
                    time_unix_seconds = int(time[0])

                    # adjust for start time
                    time_adjusted_seconds = time_unix_seconds - start_time

                    # grab microseconds
                    time_microseconds = int(time[1])

                    # compute total microseconds
                    time_total = time_adjusted_seconds * MICROSECONDS_PER_SECOND + time_microseconds

                    # set time to first payload for this flow if it hasn't been set yet
                    if flow_dict["flows"][flow_mm_seed_firstPayload]["first_payload"] == None:

                        flow_dict["flows"][flow_mm_seed_firstPayload]["first_payload"] = time_total

                    # add info to stream dict
                    if stream_dict["streams"][stream_mm_seed_firstPayload]["first_payload"] == None:

                        stream_dict["streams"][stream_mm_seed_firstPayload]["first_payload"] = time_total

                        time_to_first_payload = stream_dict["streams"][stream_mm_seed_firstPayload]["first_payload"] - \
                            stream_dict["streams"][stream_mm_seed_firstPayload]["time_created"]

                        flow_dict["flows"][flow_mm_seed_firstPayload]["time_to_first_payload_streams"].append(
                            time_to_first_payload)

                        stream_dict["ordered_events"].append(
                            ("FIRST_PAYLOAD", time_total, stream_mm_seed_firstPayload))

                    stream_mm_seed_firstPayload = None
                    flow_mm_seed_firstPayload = None

                # track info about stream completion
                elif (client_line_chunks[5] == "[tgenmarkovmodel_getNextObservation]") and client_line_chunks[8] == "'tgen.tor-packetmodel-ccs2018.graphml'" and client_line_chunks[12] == "OBSERVATION_END":
                    """
                    2000-01-01 00:05:01 946685101.176532 [message] [tgen-markovmodel.c:1465] [tgenmarkovmodel_getNextObservation] Markov model 'tgen.tor-packetmodel-ccs2018.graphml' seed 3245152722 found OBSERVATION_END with delay of 0 microseconds
                    """

                    stream_mm_seed_finishStream: int = int(
                        client_line_chunks[10])

                    flow_mm_seed_finishStream: int = streammodel_seed_to_flowmmodel_seed[
                        stream_mm_seed_finishStream]

                    # decrement the number of active streams on this flow
                    flow_dict["flows"][flow_mm_seed_finishStream]["num_streams"] -= 1

                    # split time_unix_seconds.time_microseconds
                    time = client_line_chunks[2].split(".")

                    # grab unix seconds
                    time_unix_seconds = int(time[0])

                    # adjust for start time
                    time_adjusted_seconds = time_unix_seconds - start_time

                    # grab microseconds
                    time_microseconds = int(time[1])

                    # compute total microseconds
                    time_total = time_adjusted_seconds * MICROSECONDS_PER_SECOND + time_microseconds

                    # update stream_dict
                    stream_dict["streams"][stream_mm_seed_finishStream]["finish"] = time_total

                    stream_dict["ordered_events"].append((
                        "COMPLETE", time_total, stream_mm_seed_finishStream))

                    if flow_dict["flows"][flow_mm_seed_finishStream]["num_streams"] == 0 and flow_dict["flows"][flow_mm_seed_finishStream]["all_streams_created"] == True:

                        # we just keep overwriting it so that in the end, "completion_time" will correspond to the finish time of the last stream created by this flow
                        flow_dict["flows"][flow_mm_seed_finishStream]["time_completed"] = time_total

                        flow_dict["ordered_events"].append(
                            ("COMPLETE", time_total, flow_mm_seed_finishStream))

                    stream_mm_seed_finishStream = None
                    flow_mm_seed_finishStream = None

                elif client_line_chunks[3] == "[critical]":

                    fail = True

                    break

            if fail == False:

                # now create the entry for this trace in data_dict
                data_dict[ind] = dict()

                data_dict[ind]["idle_time_stream_creation"] = compute_idle_time(
                    flow_dict["ordered_events"])

                data_dict[ind]["idle_time_first_payload"] = compute_idle_time(
                    stream_dict["ordered_events"])

                data_dict[ind]["flow_durations"], data_dict[ind]["inter_flow_generation_intervals"], data_dict[ind]["med_time_to_first_payload_streams"] = get_flow_stats(
                    flow_dict["flows"])

                ind += 1

    print(f"Consumed {ind} fail-free files!")

    # write back to file
    filename = f"{home_dir}/tgen-traces/tgen-traffic-results/flow_stats.json"

    with open(filename, "w") as f:
        json.dump(data_dict, f)
